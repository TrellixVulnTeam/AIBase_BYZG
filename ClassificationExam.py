# -*- coding: utf-8 -*-
"""TrialClassificationExam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NfOh891UqiBVpcey-5_De9M35aMht8VX

# Trial Classification Exam
"""

import warnings
warnings.filterwarnings('ignore') # uncomment this line to suppress warnings

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, accuracy_score
from sklearn.svm import SVC
from sklearn.linear_model import Perceptron
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
print(__doc__) # print information included in the triple quotes at the beginning

# Loading a standard dataset
#dataset = datasets.load_digits()
dataset = datasets.fetch_olivetti_faces()
#dataset = datasets.fetch_covtype()
#dataset = datasets.load_iris()
#dataset = datasets.load_wine()
#dataset = datasets.load_breast_cancer()

data = dataset.data
target = dataset.target

Xtrain, Xtest, ytrain, ytest = train_test_split(data, target, train_size=0.3)
print("Training on %d examples" % len(Xtrain))

df = pd.DataFrame(data)
#df.hist()
#sns.pairplot(df)

"""## Decision Tree"""

dtc = DecisionTreeClassifier(criterion='entropy')
dtc.fit(Xtrain, ytrain)
max_depth = dtc.tree_.max_depth
print(max_depth)
ptest = dtc.predict(Xtest)
print(accuracy_score(ytest, ptest))
plot_tree(dtc);

avg_scores = []
for i in range(1, max_depth+1):
  dtc = DecisionTreeClassifier(criterion='entropy', max_depth=i)
  scores = cross_val_score(dtc, Xtrain, ytrain, scoring='accuracy', cv = 5)

  avg_scores.append(np.mean(scores))

best_depth = np.argmax(avg_scores)+1
plt.figure(figsize=(22,15))
plt.plot(range(1, max_depth+1), avg_scores, '-o', linewidth=5, markersize=24)
plt.xlabel('max_depth')
plt.ylabel('accuracy')
plt.title("Score with Cross Validation varying max_depth of tree", fontsize = 24)
plt.show();
print(best_depth)

# using best depth
dtc = DecisionTreeClassifier(criterion='entropy', max_depth=best_depth)
dtc.fit(Xtrain, ytrain)
ytest = dtc.predict(Xtest)

plot_tree(dtc)

"""# Gaussian Naive Bayes"""

gnb = GaussianNB()
gnb.fit(Xtrain, ytrain)
ygnb = gnb.predict(Xtest)

print(accuracy_score(ytest, ygnb))

"""# Support Vector Machine"""

svm = SVC()
svm.fit(Xtrain, ytrain)
ysvm = svm.predict(Xtest)

print(accuracy_score(ytest, ysvm))

"""# Linear Perceptron"""

per = Perceptron()
per.fit(Xtrain, ytrain)
yper = per.predict(Xtest)

print(accuracy_score(ytest, yper))

"""# Multi Layer Perceptron"""

mlp = MLPClassifier()
mlp.fit(Xtrain, ytrain)
ymlp = mlp.predict(Xtest)

print(accuracy_score(ytest, ymlp))